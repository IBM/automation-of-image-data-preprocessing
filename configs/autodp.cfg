[general_param]
fc_size = [386]
learning_rate = 5.403871780053894e-05
reg_coef = 0.004020485630264683
kernel_size = [[1, 2, 3, 1], [1, 1, 1, 1], [1, 2, 1, 1]]
kernel_stride = [[1, 2, 3, 1], [1, 1, 1, 1], [1, 2, 1, 1]]
pool_size = [[1, 2, 3, 1], [1, 1, 1, 1], [1, 2, 1, 1]]
pool_stride = [[1, 2, 3, 1], [1, 1, 1, 1], [1, 2, 1, 1]]
train_path = /Users/minhtn/ibm/projects/autodp/data/origin
valid_path = /Users/minhtn/ibm/projects/autodp/data/origin
test_path = /Users/minhtn/ibm/projects/autodp/data/origin
prep_path = /Users/minhtn/ibm/projects/autodp/data
result_path = /Users/minhtn/ibm/projects/autodp/result
save_model = /Users/minhtn/ibm/projects/autodp/result
ima_height = 32
ima_width = 32
ima_depth = 3
num_class = 10
num_epoch = 2
batch_size = 4
keep_prob = 0.5
max_grad_norm = 3
valid_step = 4
reader = autodp.reader.sq_reader.SQReader

[rl_param]
gamma = 0.9656512944316229
max_age = 9
rl_arch = autodp.network.arch.rl.dual_q_arch.DualQArch
rl_loss = autodp.network.loss.mse.MSE
rl_graph = autodp.network.graph.rl.value_base.q2_graph.Q2Graph
rl_agent = autodp.rl_core.agent.value_base.dual_q.DualQ
rl_action = autodp.rl_core.env.action.simple_action.SimpleAction
num_action = 17
max_explore = 1
min_explore = 0.1
anneal_step = 50000

[nn_param]
nn_arch = autodp.network.arch.nn.nn_arch.NNArch
nn_loss = autodp.network.loss.sce.SCE

